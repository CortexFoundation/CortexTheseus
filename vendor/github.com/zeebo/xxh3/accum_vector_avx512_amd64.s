// Code generated by command: go run gen.go -avx512 -out ../accum_vector_avx512_amd64.s -pkg xxh3. DO NOT EDIT.

#include "textflag.h"

DATA prime_avx512<>+0(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+8(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+16(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+24(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+32(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+40(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+48(SB)/8, $0x000000009e3779b1
DATA prime_avx512<>+56(SB)/8, $0x000000009e3779b1
GLOBL prime_avx512<>(SB), RODATA|NOPTR, $64

// func accumAVX512(acc *[8]uint64, data *byte, key *byte, len uint64)
// Requires: AVX, AVX512F, MMX+
TEXT Â·accumAVX512(SB), NOSPLIT, $0-32
	MOVQ      acc+0(FP), AX
	MOVQ      data+8(FP), CX
	MOVQ      key+16(FP), DX
	MOVQ      len+24(FP), BX
	VMOVDQU64 (AX), Z1
	VMOVDQU64 prime_avx512<>+0(SB), Z0
	VMOVDQU64 (DX), Z3
	VMOVDQU64 8(DX), Z4
	VMOVDQU64 16(DX), Z5
	VMOVDQU64 24(DX), Z6
	VMOVDQU64 32(DX), Z7
	VMOVDQU64 40(DX), Z8
	VMOVDQU64 48(DX), Z9
	VMOVDQU64 56(DX), Z10
	VMOVDQU64 64(DX), Z11
	VMOVDQU64 72(DX), Z12
	VMOVDQU64 80(DX), Z13
	VMOVDQU64 88(DX), Z14
	VMOVDQU64 96(DX), Z15
	VMOVDQU64 104(DX), Z16
	VMOVDQU64 112(DX), Z17
	VMOVDQU64 120(DX), Z18
	VMOVDQU64 128(DX), Z19
	VMOVDQU64 121(DX), Z20

accum_large:
	CMPQ       BX, $0x00000400
	JLE        accum
	VMOVDQU64  (CX), Z21
	PREFETCHT0 1024(CX)
	VPXORD     Z3, Z21, Z2
	VPSHUFD    $0x31, Z2, Z22
	VPMULUDQ   Z2, Z22, Z2
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  64(CX), Z21
	PREFETCHT0 1088(CX)
	VPXORD     Z4, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  128(CX), Z21
	PREFETCHT0 1152(CX)
	VPXORD     Z5, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  192(CX), Z21
	PREFETCHT0 1216(CX)
	VPXORD     Z6, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  256(CX), Z21
	PREFETCHT0 1280(CX)
	VPXORD     Z7, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  320(CX), Z21
	PREFETCHT0 1344(CX)
	VPXORD     Z8, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  384(CX), Z21
	PREFETCHT0 1408(CX)
	VPXORD     Z9, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  448(CX), Z21
	PREFETCHT0 1472(CX)
	VPXORD     Z10, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  512(CX), Z21
	PREFETCHT0 1536(CX)
	VPXORD     Z11, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  576(CX), Z21
	PREFETCHT0 1600(CX)
	VPXORD     Z12, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  640(CX), Z21
	PREFETCHT0 1664(CX)
	VPXORD     Z13, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  704(CX), Z21
	PREFETCHT0 1728(CX)
	VPXORD     Z14, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  768(CX), Z21
	PREFETCHT0 1792(CX)
	VPXORD     Z15, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  832(CX), Z21
	PREFETCHT0 1856(CX)
	VPXORD     Z16, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  896(CX), Z21
	PREFETCHT0 1920(CX)
	VPXORD     Z17, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VMOVDQU64  960(CX), Z21
	PREFETCHT0 1984(CX)
	VPXORD     Z18, Z21, Z22
	VPSHUFD    $0x31, Z22, Z23
	VPMULUDQ   Z22, Z23, Z22
	VPSHUFD    $0x4e, Z21, Z21
	VPADDQ     Z2, Z22, Z2
	VPADDQ     Z1, Z21, Z1
	VPADDQ     Z1, Z2, Z1
	ADDQ       $0x00000400, CX
	SUBQ       $0x00000400, BX
	VPSRLQ     $0x2f, Z1, Z2
	VPTERNLOGD $0x96, Z1, Z19, Z2
	VPMULUDQ   Z0, Z2, Z1
	VPSHUFD    $0xf5, Z2, Z2
	VPMULUDQ   Z0, Z2, Z2
	VPSLLQ     $0x20, Z2, Z2
	VPADDQ     Z1, Z2, Z1
	JMP        accum_large

accum:
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z3, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z4, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z5, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z6, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z7, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z8, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z9, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z10, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z11, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z12, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z13, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z14, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z15, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z16, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z17, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX
	CMPQ      BX, $0x40
	JLE       finalize
	VMOVDQU64 (CX), Z0
	VPXORD    Z18, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1
	ADDQ      $0x00000040, CX
	SUBQ      $0x00000040, BX

finalize:
	CMPQ      BX, $0x00
	JE        return
	SUBQ      $0x40, CX
	ADDQ      BX, CX
	VMOVDQU64 (CX), Z0
	VPXORD    Z20, Z0, Z2
	VPSHUFD   $0x31, Z2, Z3
	VPMULUDQ  Z2, Z3, Z2
	VPSHUFD   $0x4e, Z0, Z0
	VPADDQ    Z1, Z2, Z1
	VPADDQ    Z1, Z0, Z1

return:
	VMOVDQU64 Z1, (AX)
	VZEROUPPER
	RET
